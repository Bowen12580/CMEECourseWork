Starting code feedback for Bowen, Week3

Current Points = 100

Note that: 
(1) Major sections begin with a double "====" line 
(2) Subsections begin with a single "====" line 
(3) Code output or text file content are printed within single "*****" lines 

======================================================================
======================================================================
Your Git repo size this week is about 12.29 MiB on disk 

PART 1: Checking project workflow...

Found the following directories in parent directory: .git, week1, week2, miniproject, Feedback, week3, week7

Found the following files in parent directory: .gitignore, README.md

Checking for key files in parent directory...

Found .gitignore in parent directory, great! 

Printing contents of .gitignore:

**********************************************************************
# Ignore all compiled/generated files and directories
*.pdf
*.log
*.aux
*.out

# Ignore all temporary files
*~

# Ignore files and directories generated by IDEs
.idea/
.vscode/

# Ignore files generated by the operating system
.DS_Store
Thumbs.db

# Ignore the contents of the compiled output directory
/results/*

**********************************************************************

Found README in parent directory, named: README.md

Printing contents of README.md:

**********************************************************************
# CMEECourseWork

## Author

Bowen Duan

## Overview

**This repository contains the content of the first term computing weeks** 

## Versions

R: 4.3.2

Python: 3.10.12



## Contact

bd623@imperial.ac.uk

# CMEE Coursework Groupwork Repository

## Group5: Bowen Duan, Chufan Wu, Hongyuan Guo, Robert Temea, Yi Yu

## List of scripts

1. **align_seqs_better.py** in week2/code
2. **align_seqs_fasta.py** in week2/code
3. **oaks_debugme_group.py** in week2/code
4. **get_TreeHeight.R** in week3/code
5. **get_TreeHeight.py** in week3/code
6. **run_get_TreeHeight.sh** in week3/code
7. **TAutoCorr.R** in week3/code
8. **FloridaAutoCorr.tex** in week3/code
9. **PP_Regress_loc.R** in week3/code

## Script Summary

1. align_seqs_better.py


    This code is used to analyze the matching between two DNA sequences by comparing their character sequences, finding the best matching starting position, and calculating the matching score. It then stores the best matching result along with its corresponding score in the **results** directory.

2. align_seqs_fasta.py


    This code performs sequence alignment between two DNA sequences loaded from FASTA files, identifying the best matching alignment and saving it along with its score in the **results** directory.

3. oaks_debugme_group.py

    This code processes a CSV file containing biological data, specifically focusing on identifying and extracting rows related to oak species, and then writes this filtered data to a new CSV file and save in the **results** directory.

4. get_TreeHeight.R

    This R script includes a TreeHeight function for calculating tree heights using trigonometry, based on tree distance and angle. It reads tree data from a CSV file, adds calculated heights to the dataframe, and saves it as a new CSV, named after the input file's basename.

5. get_TreeHeight.py

    Similar to the R version, this Python script features a TreeHeight function for computing tree heights from tree base distance and top angle. It loads data from a CSV into a pandas dataframe, appends height calculations, and exports it as a new CSV, using the input file's basename for naming.

6. run_get_TreeHeight.sh

    A shell script that executes both the R and Python scripts for tree height calculation. It processes an externally provided dataset, with both scripts producing a CSV file with calculated tree heights, saved in the **results** directory.

7. TAutoCorr.R

    This code begins by loading an RData file containing Key West annual mean temperature data and calculates the correlation coefficient between consecutive years of temperature data. It then performs a specified number of permutations of the temperature data, calculating the correlation coefficient for each permutation. Finally, the code computes an approximate p-value, creates visualizations of the original temperature data and the distribution of correlation coefficients after permutations, and prints the results.

8. FloridaAutoCorr.tex

    This document presents a permutation analysis to establish significant temperature correlations between successive years in Key West, Florida during the 20th century. It discusses the methodology used and reports the results, including a significant positive correlation between temperature and year.

9. PP_Regress_loc.R


    This code conducts linear regression analysis on data, converting units from milligrams to grams and saving the results to a CSV file in the **results** directory.






**********************************************************************

======================================================================
Looking for the weekly directories...

Found 4 weekly directories: week1, week2, week3, week7

The Week3 directory will be assessed 

======================================================================
======================================================================
PART 2: Checking weekly code and workflow...

======================================================================
Assessing WEEK3...

Found the following directories: sandbox, results, data, code

Found the following files: README.md

Checking for readme file in weekly directory...

Found README in parent directory, named: README.md

Printing contents of README.md:

**********************************************************************
# Week3
## Author

Bowen Duan

## Overview

**Code** contains the scripts.

**Data** contains data needed to run those scripts.

**Results** is where the output from those scripts is sent to.

**Sandbox** is a miscellaneous directory containing experimental code and data.

## Versions

R: 4.3.2

Python: 3.10.12

## List of Scripts
**Here contain R_Chapter and R_Visualization_Chapter codes**

- `apply1.R`: Demonstrates the use of `apply` function on a matrix to calculate row and column means and variances.
- `apply2.R`: Implements a custom operation using `apply` on a matrix, demonstrating conditional logic within the applied function.
- `basic_io.R`: Illustrates basic input-output operations in R, including reading and writing CSV files and manipulating data frames.
- `boilerplate.R`: A template script in R with a defined function, showcasing function definition, argument handling, and output.
- `break.R`: Demonstrates the use of the `break` statement within a while loop to control loop execution.
- `browse.R`: Shows the use of `browser()` function in a loop for debugging and examining code execution step by step.
- `control_flow.R`: Contains examples of control flow constructs in R like if-else statements and for loops.
- `DataWrang.R`: Script for wrangling the Pound Hill dataset, including loading, inspecting, and manipulating the data.
- `DataWrangTidy.R`: Demonstrates data wrangling using the `tidyverse` package, with operations such as data transposition and modification.
- `Florida.R`: Analyzes the Key West Annual Mean Temperature dataset, including calculating correlation coefficients and performing a permutation test.
- `FloridaAutoCorr_writeup.pdf`: Include compiled content of group work.
- `FloridaAutoCorr_writeup.tex`: Contains latex code of group work
- `FloridaReport.pdf`: Include compiled content of practical question Florida
- `FloridaReport.tex`: Contains latex code of practical question Florida
- `get_TreeHeight.py`: A Python script to calculate tree height using trigonometry from angles and distance measurements in a CSV file.
- `get_TreeHeight.R`: An R script equivalent of the Python version for calculating tree height using trigonometry based on angle and distance.
- `Girko.R`: Demonstrates the Girkoâ€™s circular law through eigenvalue distribution of a random matrix, visualizing the result in a plot.
- `GPDD_Data.R`: Loads and maps the Global Population Dynamics Database (GPDD) data, highlighting geographic distribution of data points.
- `MyBars.R`: Creates bar plots in R using `ggplot2` with data from a text file, including customization of plot elements.
- `next.R`: Utilizes the `next` statement in R within a loop to skip iterations under certain conditions.
- `plotLin.R`: Executes linear regression on simulated data and visualizes the results with color-coded residuals in a scatter plot.
- `PP_Dists.R`: Analyzes and visualizes the distribution of predator-prey mass ratios in an ecological dataset using `ggplot2` and `dplyr`.
- `PP_Regress.R`: Utilizes `ggplot2` and `dplyr` for data visualization and analysis. It reads ecological data, then creates a plot with linear regression lines to examine the relationship between predator and prey mass, distinguishing by the type of feeding interaction and predator life stage.
- `PP_Regress_loc.R`: Conducts linear regression analysis on predator-prey mass data, adjusting for unit differences and summarizing results.
- `preallocate.R`: Compares performance between preallocated and dynamically growing vectors in R, illustrating efficiency in memory management.
- `R_conditionals.R`: Demonstrates the use of conditional statements in R, including functions to check if a number is even, a power of two, or prime.
- `Ricker.R`: Implements the Ricker model to simulate population dynamics over generations and plots the result.
- `run_get_TreeHeight.sh`: A shell script that runs both R and Python scripts (`get_TreeHeight.R` and `get_TreeHeight.py`) to calculate tree heights.
- `sample.R`: Illustrates sampling techniques in R, including the use of loops and functions to compute sample means from a population.
- `TAutoCorr.R`: Analyzes temperature autocorrelation in Key West Annual Mean Temperature data using permutation testing for correlation coefficients.
- `TreeHeight.R`: Calculates tree heights using trigonometry from angle and distance data in a CSV file, and outputs the results to a new file.
- `try.R`: Demonstrates error handling in R with a function that calculates the mean of a sample, using `try` to catch exceptions for insufficient unique values.
- `Vectorize1.R`: Compares the performance of a double loop and vectorized function for summing all elements in a large matrix.
- `Vectorize2.R`: Implements the stochastic Ricker model with Gaussian fluctuations, illustrating the use of matrix operations for population dynamics simulation.




## Contact

bd623@imperial.ac.uk

**********************************************************************

Results directory is empty - good! 

Found 32 code files: PP_Dists.R, Vectorize2.R, FloridaReport.tex, break.R, sample.R, Vectorize1.R, PP_Regress.R, FloridaAutoCorr_writeup.tex, PP_Regress_loc.R, R_conditionals.R, apply1.R, basic_io.R, GPDD_Data.R, TAutoCorr.R, Girko.R, run_get_TreeHeight.sh, Florida.R, DataWrangTidy.R, boilerplate.R, apply2.R, DataWrang.R, try.R, control_flow.R, Ricker.R, MyBars.R, TreeHeight.R, get_TreeHeight.py, plotLin.R, next.R, get_TreeHeight.R, browse.R, preallocate.R

Found the following extra files: FloridaReport.pdf, FloridaAutoCorr_writeup.pdf
0.5 pt deducted per extra file

Current Points = 99.0

======================================================================
Testing script/code files...

======================================================================
Inspecting script file PP_Dists.R...

File contents are:

**********************************************************************
# Load the necessary libraries
library(ggplot2)
library(dplyr)

# Read the data
data <- read.csv("../data/EcolArchives-E089-51-D1.csv")

# Calculate logarithmic values
data <- data %>%
  mutate(log_predator_mass = log(Predator.mass),
         log_prey_mass = log(Prey.mass),
         log_size_ratio = log(Prey.mass / Predator.mass))

# Calculate statistics for each type of feeding interaction
results <- data %>%
  group_by(Type.of.feeding.interaction) %>%
  summarise(
    mean_log_predator_mass = mean(log_predator_mass, na.rm=TRUE),
    median_log_predator_mass = median(log_predator_mass, na.rm=TRUE),
    mean_log_prey_mass = mean(log_prey_mass, na.rm=TRUE),
    median_log_prey_mass = median(log_prey_mass, na.rm=TRUE),
    mean_log_size_ratio = mean(log_size_ratio, na.rm=TRUE),
    median_log_size_ratio = median(log_size_ratio, na.rm=TRUE)
  )

# Save the statistical data to a CSV file
write.csv(results, "../results/PP_Results.csv", row.names = FALSE)

# Create and save histograms
feeding_types <- unique(data$Type.of.feeding.interaction)

# Create histograms for predator mass
pdf("../results/Pred_Subplots.pdf")
par(mfrow = c(3, 2))
for(feeding_type in feeding_types) {
  hist(subset(data, Type.of.feeding.interaction == feeding_type)$log_predator_mass,
       main = paste("Predator Mass -", feeding_type),
       xlab = "Log(Predator Mass)")
}
dev.off()

# Create histograms for prey mass
pdf("../results/Prey_Subplots.pdf")
par(mfrow = c(3, 2))
for(feeding_type in feeding_types) {
  hist(subset(data, Type.of.feeding.interaction == feeding_type)$log_prey_mass,
       main = paste("Prey Mass -", feeding_type),
       xlab = "Log(Prey Mass)")
}
dev.off()

# Create histograms for size ratio
pdf("../results/SizeRatio_Subplots.pdf")
par(mfrow = c(3, 2))
for(feeding_type in feeding_types) {
  hist(subset(data, Type.of.feeding.interaction == feeding_type)$log_size_ratio,
       main = paste("Size Ratio -", feeding_type),
       xlab = "Log(Size Ratio)")
}
dev.off()

**********************************************************************

Testing PP_Dists.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Error in library(ggplot2) : there is no package called â€˜ggplot2â€™
Execution halted

======================================================================
Inspecting script file Vectorize2.R...

File contents are:

**********************************************************************
# Runs the stochastic Ricker equation with gaussian fluctuations

rm(list = ls())

stochrick <- function(p0 = runif(1000, .5, 1.5), r = 1.2, K = 1, sigma = 0.2,numyears = 100)
{

  N <- matrix(NA, numyears, length(p0))  #initialize empty matrix

  N[1, ] <- p0

  for (pop in 1:length(p0)) { #loop through the populations

    for (yr in 2:numyears){ #for each pop, loop through the years

      N[yr, pop] <- N[yr-1, pop] * exp(r * (1 - N[yr - 1, pop] / K) + rnorm(1, 0, sigma)) # add one fluctuation from normal distribution
    
     }
  
  }
 return(N)

}
print("Stochastic Ricker takes:")
print(system.time(res1<-stochrick()))

# Now write another function called stochrickvect that vectorizes the above to
# the extent possible, with improved performance: 

stochrickvect <- function(p0 = runif(1000, .5, 1.5), r = 1.2, K = 1, sigma = 0.2,numyears = 100) {
  
  # initial matrix
  N <- matrix(NA, numyears, length(p0))
  
  # Store the initial number of individuals in the matrix rows for the first year
  N[1, ] <- p0
  
  # Modelling the stochastic Ricker equation using matrix operations to add fluctuations from a normal distribution
  for (yr in 2:numyears) {
    N[yr, ] <- N[yr-1, ] * exp(r * (1 - N[yr - 1, ] / K) + rnorm(length(p0), 0, sigma))
  }
  

  return(N)
}


print("Vectorized Stochastic Ricker takes:")
print(system.time(res2<-stochrickvect()))

# print("Vectorized Stochastic Ricker takes:")
# print(system.time(res2<-stochrickvect()))
**********************************************************************

Testing Vectorize2.R...

Output (only first 500 characters): 


**********************************************************************
[1] "Stochastic Ricker takes:"
   user  system elapsed 
  0.111   0.020   0.144 
[1] "Vectorized Stochastic Ricker takes:"
   user  system elapsed 
  0.006   0.000   0.007 

**********************************************************************

Code ran without errors

Time consumed = 0.26773s

======================================================================
Inspecting script file FloridaReport.tex...

File contents are:

**********************************************************************
\documentclass[10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage[margin=1in]{geometry}
\linespread{0.9}
\title{Climate Trend Analysis: Is Florida Getting Warmer?}
\author{Bowen Duan}

\begin{document}

\maketitle

\section{Introduction}
This report examines historical temperature data to answer the question: is Florida warming? By analyzing the temperature trends in Key West, Florida, I conclude that there is an upward trend in temperatures over the 20th century.

\section{Methods}
I conducted a permutation analysis to calculate the correlation coefficient between time and temperature, accounting for the serial dependence in the time-series data. This method shuffles the temperature data points and recalculates the correlation coefficient 1000 times to create a distribution of correlation coefficients under the null hypothesis of no relationship between time and temperature.

\section{Visualization}
\begin{figure}[ht]
\centering
\begin{minipage}{0.4\textwidth}
  \centering
  \includegraphics[width=\linewidth]{../results/results.png}
  \caption{This can be learned by looking at the trend line added to the graph. The trend in average annual temperatures for Key West shows a significant increase in average annual temperatures since the 20th century, showing that Key West's climate is warming.}
  \label{fig:temp_trend}
\end{minipage}
\hfill
\begin{minipage}{0.4\textwidth}
  \centering
  \includegraphics[width=\linewidth]{../results/cor.png}
  \caption{It is clear from the histogram that the random correlation coefficient is much smaller than the observed correlation coefficient, so it can be concluded that the value of p value is very small}
  \label{fig:corr_dist}
\end{minipage}
\end{figure}

\section{Conclusion}
The statistical analysis clearly indicates that Florida is experiencing a warming trend. The observed correlation coefficient significantly exceeds the distribution of coefficients under the null hypothesis, with a p-value less than 0.0001. This analysis confirms that the temperatures in Key West have risen significantly over the past century.

\end{document}


**********************************************************************

Testing FloridaReport.tex...

======================================================================
Inspecting script file break.R...

File contents are:

**********************************************************************
i <- 0 #Initialize i
    while (i < Inf) {
        if (i == 10) {
            break 
        } else { # Break out of the while loop!  
            cat("i equals " , i , " \n")
            i <- i + 1 # Update i
    }
}

**********************************************************************

Testing break.R...

Output (only first 500 characters): 


**********************************************************************
i equals  0  
i equals  1  
i equals  2  
i equals  3  
i equals  4  
i equals  5  
i equals  6  
i equals  7  
i equals  8  
i equals  9  

**********************************************************************

Code ran without errors

Time consumed = 0.09184s

======================================================================
Inspecting script file sample.R...

File contents are:

**********************************************************************
######### Functions ##########

## A function to take a sample of size n from a population "popn" and return its mean
myexperiment <- function(popn,n) {
    pop_sample <- sample(popn, n, replace = FALSE)
    return(mean(pop_sample))
}

## Calculate means using a FOR loop on a vector without preallocation:
loopy_sample1 <- function(popn, n, num) {
    result1 <- vector() #Initialize empty vector of size 1 
    for(i in 1:num) {
        result1 <- c(result1, myexperiment(popn, n))
    }
    return(result1)
}

## To run "num" iterations of the experiment using a FOR loop on a vector with preallocation:
loopy_sample2 <- function(popn, n, num) {
    result2 <- vector(,num) #Preallocate expected size
    for(i in 1:num) {
        result2[i] <- myexperiment(popn, n)
    }
    return(result2)
}

## To run "num" iterations of the experiment using a FOR loop on a list with preallocation:
loopy_sample3 <- function(popn, n, num) {
    result3 <- vector("list", num) #Preallocate expected size
    for(i in 1:num) {
        result3[[i]] <- myexperiment(popn, n)
    }
    return(result3)
}


## To run "num" iterations of the experiment using vectorization with lapply:
lapply_sample <- function(popn, n, num) {
    result4 <- lapply(1:num, function(i) myexperiment(popn, n))
    return(result4)
}

## To run "num" iterations of the experiment using vectorization with sapply:
sapply_sample <- function(popn, n, num) {
    result5 <- sapply(1:num, function(i) myexperiment(popn, n))
    return(result5)
}

set.seed(12345)
popn <- rnorm(10000) # Generate the population
hist(popn)

n <- 100 # sample size for each experiment
num <- 10000 # Number of times to rerun the experiment

print("Using loops without preallocation on a vector took:" )
print(system.time(loopy_sample1(popn, n, num)))

print("Using loops with preallocation on a vector took:" )
print(system.time(loopy_sample2(popn, n, num)))

print("Using loops with preallocation on a list took:" )
print(system.time(loopy_sample3(popn, n, num)))

print("Using the vectorized sapply function (on a list) took:" )
print(system.time(sapply_sample(popn, n, num)))

print("Using the vectorized lapply function (on a list) took:" )
print(system.time(lapply_sample(popn, n, num)))

**********************************************************************

Testing sample.R...

Output (only first 500 characters): 


**********************************************************************
[1] "Using loops without preallocation on a vector took:"
   user  system elapsed 
  0.176   0.011   0.188 
[1] "Using loops with preallocation on a vector took:"
   user  system elapsed 
  0.117   0.000   0.117 
[1] "Using loops with preallocation on a list took:"
   user  system elapsed 
  0.118   0.000   0.118 
[1] "Using the vectorized sapply function (on a list) took:"
   user  system elapsed 
  0.118   0.000   0.117 
[1] "Using the vectorized lapply function (on a list) took:"
   user  syst
**********************************************************************

Code ran without errors

Time consumed = 0.85068s

======================================================================
Inspecting script file Vectorize1.R...

File contents are:

**********************************************************************
M <- matrix(runif(1000000),1000,1000)

SumAllElements <- function(M) {
  Dimensions <- dim(M)
  Tot <- 0
  for (i in 1:Dimensions[1]) {
    for (j in 1:Dimensions[2]) {
      Tot <- Tot + M[i,j]
    }
  }
  return (Tot)
}
 
print("Using loops, the time taken is:")
print(system.time(SumAllElements(M)))

print("Using the in-built vectorized function, the time taken is:")
print(system.time(sum(M)))

**********************************************************************

Testing Vectorize1.R...

Output (only first 500 characters): 


**********************************************************************
[1] "Using loops, the time taken is:"
   user  system elapsed 
  0.029   0.004   0.032 
[1] "Using the in-built vectorized function, the time taken is:"
   user  system elapsed 
  0.001   0.000   0.000 

**********************************************************************

Code ran without errors

Time consumed = 0.15588s

======================================================================
Inspecting script file PP_Regress.R...

File contents are:

**********************************************************************
# Load required packages
library(ggplot2)
library(dplyr)

# Read the data
MyDF <- read.csv("../data/EcolArchives-E089-51-D1.csv")

# Draw the plot using ggplot
plot <- ggplot(MyDF, aes(x = Prey.mass, y = Predator.mass, color = Type.of.feeding.interaction)) +
   geom_point(aes(color = Predator.lifestage), shape = "+", alpha = 1) +  # Use shape "+" for crosses
   geom_smooth(method = "lm", aes(color = Predator.lifestage), se = FALSE, fullrange = TRUE) +
   scale_y_log10(breaks = c(1e-6, 1e-2, 1e+2, 1e+6),
                labels = scales::trans_format("log10", scales::math_format(10^.x))) +
   scale_x_log10(breaks = c(1e-07, 1e-03, 1e+01),
                labels = scales::trans_format("log10", scales::math_format(10^.x))) +
   labs(x = "Prey Mass in grams",
        y = "Predator mass in grams") +
   theme_minimal() +
   theme(legend.position = "bottom",
        panel.border = element_rect(fill = NA, color = "black", linewidth = 1)) +
   guides(color = guide_legend(title = "Predator.lifestage", ncol = 6, keywidth = 1, keyheight = 1))

# Save the plot to a PDF file
pdf("../results/PP_Regress.pdf")
print(plot)
dev.off()

# Calculate regression results
results <- MyDF %>%
  group_by(Type.of.feeding.interaction) %>%
  summarize(
    slope = coef(lm(Predator.mass ~ Prey.mass))[2],
    intercept = coef(lm(Predator.mass ~ Prey.mass))[1],
    R_Square = (cor(Predator.mass, Prey.mass))^2,
    F_statistic = summary(lm(Predator.mass ~ Prey.mass))$fstatistic[1],
    p_value = summary(lm(Predator.mass ~ Prey.mass))$fstatistic[4]
  )

# Save regression results to a CSV file
write.csv(results, file = "../results/PP_Regress_Results.csv", row.names = FALSE)

**********************************************************************

Testing PP_Regress.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Error in library(ggplot2) : there is no package called â€˜ggplot2â€™
Execution halted

======================================================================
Inspecting script file FloridaAutoCorr_writeup.tex...

File contents are:

**********************************************************************
\documentclass[12pt,a4paper]{article}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{textcomp} % Added for \degree command
\usepackage{subcaption} % Added for subfigures
\usepackage[left=1cm,right=1cm,top=0cm,bottom=1cm]{geometry}

\title{Analysis of Autocorrelation in Florida Weather}
\author{Hongyuan Guo, Temea Roberts, Yi Yu, Bowen Duan, and Chufan Wu} 
\date{October 2023}

\begin{document}

\maketitle

\section{Introduction}
The purpose of this analysis is to determine whether the temperatures of one year are significantly correlated with the next year (successive years) in Key West, Florida.

\section{Methodology}
To address the inherent non-independence of successive measurements in a time series, the original correlation between successive years was compared to a distribution of correlations obtained from permuting the time series data 10000 times. As data was normally distributed, a Pearson's correlation test was used for both the original test statistic and for each permutation. 

\section{Results}
Temperature increased by 1.61\textdegree C between 1901 and 2000 (see Fig. \ref{fig:time}), with strong autocorrelation between successive years (r = 0.33, df = 97, p = \(2 \times 10^{-4}\)). 

\begin{figure}[h]
\centering
\begin{subfigure}{0.45\textwidth}
    \includegraphics[width=\textwidth]{../data/02_time.png}
    \caption{Key West annual mean temperatures throughout the 20th century}
    \label{fig:time}
\end{subfigure}
\hfill
\begin{subfigure}{0.45\textwidth}
    \includegraphics[width=\textwidth]{../data/02_corr.png}
    \caption{Distribution of correlation coefficients from permutations, with the red line representing the p-value obtained from the real data.}
    \label{fig:corr}
\end{subfigure}
\end{figure}

Correlation coefficients from permutations ranged between 0.38 and -0.40, with a mean of 0 (see Fig. \ref{fig:corr}).


\end{document}


**********************************************************************

Testing FloridaAutoCorr_writeup.tex...

======================================================================
Inspecting script file PP_Regress_loc.R...

File contents are:

**********************************************************************
# Load necessary libraries
library(plyr)

# Load the data
mydata <- read.csv("../data/EcolArchives-E089-51-D1.csv")

# Convert mg values to g
mydata$Prey.mass[mydata$Prey.mass.unit == "mg"] <- mydata$Prey.mass[mydata$Prey.mass.unit == "mg"] / 1000

# Define a function for linear regression analysis
lm_function <- function(data) {
  lm_result <- summary(lm(Prey.mass ~ Predator.mass, data = data))
  return(data.frame(
    slope = lm_result$coefficients[2],
    intercept = lm_result$coefficients[1],
    r2 = lm_result$r.squared,
    pvalue = lm_result$coefficients[8],
    fstat = lm_result$fstatistic[1]
  ))
}

# Apply linear regression function to subsets of the data
output <- ddply(mydata, .(Type.of.feeding.interaction, Predator.lifestage, Location), lm_function)

# Write the results to a CSV file
write.csv(output, "../results/PP_Regress_loc_Results.csv", row.names = FALSE)

**********************************************************************

Testing PP_Regress_loc.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Error in library(plyr) : there is no package called â€˜plyrâ€™
Execution halted

======================================================================
Inspecting script file R_conditionals.R...

File contents are:

**********************************************************************
# Checks if an integer is even
is.even <- function(n = 2) {
  if (n %% 2 == 0) {
    return(paste(n,'is even!'))
  } else {
  return(paste(n,'is odd!'))
  }
}

is.even(6)

# Checks if a number is a power of 2
is.power2 <- function(n = 2) {
  if (log2(n) %% 1==0) {
    return(paste(n, 'is a power of 2!'))
  } else {
  return(paste(n,'is not a power of 2!'))
    }
}

is.power2(4)

# Checks if a number is prime
is.prime <- function(n) {
  if (n==0) {
    return(paste(n,'is a zero!'))
  } else if (n==1) {
    return(paste(n,'is just a unit!'))
  }
    
  ints <- 2:(n-1)
  
  if (all(n%%ints!=0)) {
    return(paste(n,'is a prime!'))
  } else {
  return(paste(n,'is a composite!'))
    }
}

is.prime(3)

**********************************************************************

Testing R_conditionals.R...

Output (only first 500 characters): 


**********************************************************************
[1] "6 is even!"
[1] "4 is a power of 2!"
[1] "3 is a prime!"

**********************************************************************

Code ran without errors

Time consumed = 0.09876s

======================================================================
Inspecting script file apply1.R...

File contents are:

**********************************************************************
## Build a random matrix
M <- matrix(rnorm(100), 10, 10)

## Take the mean of each row
RowMeans <- apply(M, 1, mean)
print (RowMeans)

## Now the variance
RowVars <- apply(M, 1, var)
print (RowVars)

## By column
ColMeans <- apply(M, 2, mean)
print (ColMeans)

**********************************************************************

Testing apply1.R...

Output (only first 500 characters): 


**********************************************************************
 [1]  0.06874855 -0.12180298  0.05480549  0.29103106 -0.32831063  0.53896604
 [7] -0.04958638 -0.08814539 -0.30226244  0.63394348
 [1] 1.3005183 1.6081880 1.2332569 1.6503158 0.4224585 0.9529741 0.2505160
 [8] 2.8308213 1.1260299 1.7733662
 [1] -0.51639817  0.24850588 -0.31004905 -0.02613283  0.34568926  0.57030405
 [7] -0.27030018  0.18073023  0.44920918  0.02582841

**********************************************************************

Code ran without errors

Time consumed = 0.09884s

======================================================================
Inspecting script file basic_io.R...

File contents are:

**********************************************************************
# A simple script to illustrate R input-output.  
# Run line by line and check inputs outputs to understand what is happening  

MyData <- read.csv("../data/trees.csv", header = TRUE) # import with headers

write.csv(MyData, "../results/MyData.csv") #write it out as a new file

write.table(MyData[1,], file = "../results/MyData.csv",append=TRUE) # Append to it

write.csv(MyData, "../results/MyData.csv", row.names=TRUE) # write row names

write.table(MyData, "../results/MyData.csv", col.names=FALSE) # ignore column names
**********************************************************************

Testing basic_io.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Warning message:
In write.table(MyData[1, ], file = "../results/MyData.csv", append = TRUE) :
  appending column names to file

======================================================================
Inspecting script file GPDD_Data.R...

File contents are:

**********************************************************************
# Load required packages
library(maps)

# Load GPDD data
load("../data/GPDDFiltered.RData")

# Create world map
map("world")

# set the location points into the map shape of point is circle(by pch =16) and color is blue(by col = blue)
points(gpdd$long, gpdd$lat, col = "blue", pch = 16)

# Bias in the data analysis

# Data are too concentrated in some areas and too sparse in others, which may lead to errors in the analyses.
# Solution: average distribute points in the map may be better
**********************************************************************

Testing GPDD_Data.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Error in library(maps) : there is no package called â€˜mapsâ€™
Execution halted

======================================================================
Inspecting script file TAutoCorr.R...

File contents are:

**********************************************************************
rm(list=ls())

load("../data/KeyWestAnnualMeanTemperature.RData")

# Set seed for reproducibility 
set.seed(123)

# Calculate the correlation coefficient between consecutive years
original_corr <- cor(ats$Temp[-length(ats$Temp)], ats$Temp[-1])

# Set the number of permutations
n_permutations <- 10000

# Initialize a vector to store the correlation coefficient after permutation
permuted_corrs <- numeric(n_permutations)

# Perform permutation and calculate correlation coefficients
for(i in 1:n_permutations){
  permuted_temp <- sample(ats$Temp)
  permuted_corrs[i] <- cor(permuted_temp[-length(permuted_temp)], permuted_temp[-1])
}

# p-value
p_value <- sum(permuted_corrs > original_corr) / n_permutations

# Draw raw temperature data graph
png("../data/02_time.png")
plot(ats$Year, ats$Temp, type='l', main="Key West Annual Mean Temperature", xlab="Year", ylab=expression("Temperature ("*degree*C*")"))
dev.off()

# Draw a correlation coefficient distribution map after permutation
png("../data/02_corr.png")
hist(permuted_corrs, breaks=50, main="Distribution of Correlation Coefficients from Permutations", xlab="Correlation Coefficient")
abline(v=original_corr, col="red")
dev.off()


print(paste("Approximate p-value:", p_value))

**********************************************************************

Testing TAutoCorr.R...

Output (only first 500 characters): 


**********************************************************************
null device 
          1 
null device 
          1 
[1] "Approximate p-value: 2e-04"

**********************************************************************

Code ran without errors

Time consumed = 0.32576s

======================================================================
Inspecting script file Girko.R...

File contents are:

**********************************************************************
library(ggplot2)
build_ellipse <- function(hradius, vradius){ # function that returns an ellipse
  npoints = 250
  a <- seq(0, 2 * pi, length = npoints + 1)
  x <- hradius * cos(a)
  y <- vradius * sin(a)  
  return(data.frame(x = x, y = y))
}

N <- 250 # Assign size of the matrix

M <- matrix(rnorm(N * N), N, N) # Build the matrix

eigvals <- eigen(M)$values # Find the eigenvalues

eigDF <- data.frame("Real" = Re(eigvals), "Imaginary" = Im(eigvals)) # Build a dataframe

my_radius <- sqrt(N) # The radius of the circle is sqrt(N)

ellDF <- build_ellipse(my_radius, my_radius) # Dataframe to plot the ellipse

names(ellDF) <- c("Real", "Imaginary") # rename the columns

# plot the eigenvalues
p <- ggplot(eigDF, aes(x = Real, y = Imaginary))
p <- p +
  geom_point(shape = I(3)) +
  theme(legend.position = "none")

# now add the vertical and horizontal line
p <- p + geom_hline(aes(yintercept = 0))
p <- p + geom_vline(aes(xintercept = 0))

# finally, add the ellipse
p <- p + geom_polygon(data = ellDF, aes(x = Real, y = Imaginary, alpha = 1/20, fill = "red"))

# Save the plot as Girko.pdf in the results directory
ggsave("../results/Girko.pdf", plot = p, width = 8, height = 6)

**********************************************************************

Testing Girko.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Error in library(ggplot2) : there is no package called â€˜ggplot2â€™
Execution halted

======================================================================
Inspecting script file run_get_TreeHeight.sh...

File contents are:

**********************************************************************
# !/bin/bash

# Run R test
Rscript get_TreeHeight.R ../data/trees.csv

# Run python test
python3 get_TreeHeight.py ../data/trees.csv

# Echo the completion message
echo "Script completed. Check results directory for output."

**********************************************************************

Testing run_get_TreeHeight.sh...

Output (only first 500 characters): 


**********************************************************************
Script completed. Check results directory for output.

**********************************************************************

Code ran without errors

Time consumed = 0.13846s

======================================================================
Inspecting script file Florida.R...

File contents are:

**********************************************************************
# load the data
load("../data/KeyWestAnnualMeanTemperature.RData")

# calculate correlation coefficients
observed_corr <- cor(ats$Year, ats$Temp)

# set permutations
num_permutations <- 1000

# create a vector to save the random cor
random_corrs <- numeric(num_permutations)

# use permutation test
for (i in 1:num_permutations) {
  # use sample to make random arrangement
  shuffled_temps <- sample(ats$Temp)
  
  # store random correlation coefficient
  random_corrs[i] <- cor(ats$Year, shuffled_temps)
}

# compute p value
p_value <- sum(random_corrs > observed_corr) / num_permutations

# print p_value
print(paste("p value is:", p_value))

# explain in the png
png(filename= "../results/results.png", width = 800, height = 600)
par(mar = c(4, 4, 2, 2))
plot(ats$Year, ats$Temp, type = "l", xlab = "Year", ylab = "Temperature", main = "Key West Florida average temperature ")
abline(lm(ats$Temp ~ ats$Year), col = "red")

dev.off()



# Generate histogram of random correlation coefficients 
png(filename = "../results/cor.png", width = 800, height = 600)
# Create a histogram with a density plot
hist(random_corrs, probability = TRUE, breaks=50, xlim=range(c(random_corrs, observed_corr)), 
     main="Density and Histogram of Random Correlation Coefficients", 
     xlab="Correlation Coefficient", col="gray", border="black")
# Add a density plot
dens <- density(random_corrs)
lines(dens, col="blue", lwd=2)
# Add the observed correlation line
abline(v=observed_corr, col="darkred", lwd=2, lty=2)
# Add a legend
legend("topleft", legend=c("Random Correlation Density", "Observed Correlation"), 
       col=c("blue", "darkred"), lwd=2, lty=1:2)
dev.off()




**********************************************************************

Testing Florida.R...

Output (only first 500 characters): 


**********************************************************************
[1] "p value is: 0"
null device 
          1 
null device 
          1 

**********************************************************************

Code ran without errors

Time consumed = 0.20396s

======================================================================
Inspecting script file DataWrangTidy.R...

File contents are:

**********************************************************************
# Load required packages
library(tidyverse)

# Load the dataset
MyData <- as.matrix(read.csv("../data/PoundHillData.csv", header = FALSE))
MyMetaData <- read.csv("../data/PoundHillMetaData.csv", header = TRUE, sep = ";")

# Inspect the dataset
head(MyData)
dim(MyData)
str(MyData)
View(MyData) #you can also do this
View(MyMetaData)

# Transpose the datasetï¼ˆNo command we can replace the transpose 't' command)
MyData <- t(MyData) 
head(MyData)
dim(MyData)

# Replace species absences with zeros
MyData[MyData == ""] <- 0

# Convert raw matrix to data frame
TempData <- as.data.frame(MyData[-1,], stringsAsFactors = FALSE)
colnames(TempData) <- MyData[1,]
####################################################################################################
##########################################
# we can use gather() in the tidyverse and also pivot_longer() to replace melt() in the original code. I put the pivot_longer in the comment
MyWrangledData <- TempData %>%
  gather(key = "Species", value = "Count", -c(Cultivation, Block, Plot, Quadrat)) %>%
  mutate(across(c(Cultivation, Block, Plot, Quadrat), as.factor),
         Count = as.integer(Count))
######################################################################################################
# Convert from wide to long format (here use the 'pivot_longer' to replace the original 'melt')
#MyWrangledData <- TempData %>%
 # pivot_longer(cols = -c(Cultivation, Block, Plot, Quadrat),
  #             names_to = "Species",
   #            values_to = "Count") %>%
 # mutate(across(c(Cultivation, Block, Plot, Quadrat), as.factor),
  #       Count = as.integer(Count))

str(MyWrangledData)
head(MyWrangledData)
dim(MyWrangledData)

# Exploring the data (extend the script below)
# Continue your data exploration and analysis here using dplyr and tidyr functions
**********************************************************************

Testing DataWrangTidy.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Error in library(tidyverse) : there is no package called â€˜tidyverseâ€™
Execution halted

======================================================================
Inspecting script file boilerplate.R...

File contents are:

**********************************************************************
# A boilerplate R script

MyFunction <- function(Arg1, Arg2) {
  
  # Statements involving Arg1, Arg2:
  print(paste("Argument", as.character(Arg1), "is a", class(Arg1))) # print Arg1's type
  print(paste("Argument", as.character(Arg2), "is a", class(Arg2))) # print Arg2's type
    
  return (c(Arg1, Arg2)) #this is optional, but very useful
}

MyFunction(1,2) #test the function
MyFunction("Riki","Tiki") #A different test
**********************************************************************

Testing boilerplate.R...

Output (only first 500 characters): 


**********************************************************************
[1] "Argument 1 is a numeric"
[1] "Argument 2 is a numeric"
[1] 1 2
[1] "Argument Riki is a character"
[1] "Argument Tiki is a character"
[1] "Riki" "Tiki"

**********************************************************************

Code ran without errors

Time consumed = 0.09880s

======================================================================
Inspecting script file apply2.R...

File contents are:

**********************************************************************
SomeOperation <- function(v) { # (What does this function do?)
  if (sum(v) > 0) { #note that sum(v) is a single (scalar) value
    return (v * 100)
  } else { 
  return (v)
    }
}

M <- matrix(rnorm(100), 10, 10)
print (apply(M, 1, SomeOperation))

**********************************************************************

Testing apply2.R...

Output (only first 500 characters): 


**********************************************************************
           [,1]        [,2]       [,3]         [,4]       [,5]        [,6]
 [1,]  81.68038   39.859524   41.78261 -0.154521974  1.5115102   -2.242132
 [2,] -90.31343  -34.790492   38.91071 -0.510526682  0.1511083 -110.750755
 [3,] -43.04106  208.918229  -71.17087 -0.353149007 -1.1351781   -3.614293
 [4,]  60.67291    1.461909  240.17414  0.343293440 -2.0010509  -13.535976
 [5,]  77.57489  120.185581  -33.42663 -0.014237832 -1.3068210   11.064660
 [6,] 149.15108  -78.245866  -76.17421  0.887521113
**********************************************************************

Code ran without errors

Time consumed = 0.09671s

======================================================================
Inspecting script file DataWrang.R...

File contents are:

**********************************************************************
################################################################
################## Wrangling the Pound Hill Dataset ############
################################################################

############# Load the dataset ###############
# header = false because the raw data don't have real headers
MyData <- as.matrix(read.csv("../data/PoundHillData.csv", header = FALSE))

# header = true because we do have metadata headers
MyMetaData <- read.csv("../data/PoundHillMetaData.csv", header = TRUE, sep = ";")

############# Inspect the dataset ###############
head(MyData)
dim(MyData)
str(MyData)
fix(MyData) #you can also do this
fix(MyMetaData)

############# Transpose ###############
# To get those species into columns and treatments into rows 
MyData <- t(MyData) 
head(MyData)
dim(MyData)

############# Replace species absences with zeros ###############
MyData[MyData == ""] = 0

############# Convert raw matrix to data frame ###############

TempData <- as.data.frame(MyData[-1,],stringsAsFactors = F) #stringsAsFactors = F is important!
colnames(TempData) <- MyData[1,] # assign column names from original data

############# Convert from wide to long format  ###############
require(reshape2) # load the reshape2 package

?melt #check out the melt function

MyWrangledData <- melt(TempData, id=c("Cultivation", "Block", "Plot", "Quadrat"), variable.name = "Species", value.name = "Count")

MyWrangledData[, "Cultivation"] <- as.factor(MyWrangledData[, "Cultivation"])
MyWrangledData[, "Block"] <- as.factor(MyWrangledData[, "Block"])
MyWrangledData[, "Plot"] <- as.factor(MyWrangledData[, "Plot"])
MyWrangledData[, "Quadrat"] <- as.factor(MyWrangledData[, "Quadrat"])
MyWrangledData[, "Count"] <- as.integer(MyWrangledData[, "Count"])

str(MyWrangledData)
head(MyWrangledData)
dim(MyWrangledData)

############# Exploring the data (extend the script below)  ###############

**********************************************************************

Testing DataWrang.R...

Output (only first 500 characters): 


**********************************************************************
     V1                     V2        V3        V4        V5        V6       
[1,] "Cultivation"          "october" "october" "october" "october" "october"
[2,] "Block"                "a"       "a"       "a"       "a"       "a"      
[3,] "Plot"                 "1"       "1"       "1"       "1"       "1"      
[4,] "Quadrat"              "Q1"      "Q2"      "Q3"      "Q4"      "Q5"     
[5,] "Achillea millefolium" "4"       "8"       "3"       "20"      "6"      
[6,] "Agrostis gigantea"    ""   
**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Loading required package: reshape2
Warning message:
In library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE,  :
  there is no package called â€˜reshape2â€™
Error in melt(TempData, id = c("Cultivation", "Block", "Plot", "Quadrat"),  : 
  could not find function "melt"
Execution halted

======================================================================
Inspecting script file try.R...

File contents are:

**********************************************************************
doit <- function(x) {
    temp_x <- sample(x, replace = TRUE)
    if(length(unique(temp_x)) > 30) {#only take mean if sample was sufficient
         print(paste("Mean of this sample was:", as.character(mean(temp_x))))
        } 
    else {
        stop("Couldn't calculate mean: too few unique values!")
        }
    }


set.seed(1345) # again, to get the same result for illustration
popn <- rnorm(50)
hist(popn)

# Use 'TRUE' replace 'False'
result <- vector("list", 15) #Preallocate/Initialize
for(i in 1:15) {
    result[[i]] <- try(doit(popn), TRUE)
    }
**********************************************************************

Testing try.R...

Output (only first 500 characters): 


**********************************************************************
[1] "Mean of this sample was: -0.11620822588674"
[1] "Mean of this sample was: -0.0468516755995931"
[1] "Mean of this sample was: -0.0890228211466614"
[1] "Mean of this sample was: -0.124229742255296"
[1] "Mean of this sample was: 0.0314144452816157"
[1] "Mean of this sample was: -0.233476945796405"
[1] "Mean of this sample was: -0.196681538928001"
[1] "Mean of this sample was: 0.0146969612111605"
[1] "Mean of this sample was: -0.234913159471725"
[1] "Mean of this sample was: -0.0497464588165691"
**********************************************************************

Code ran without errors

Time consumed = 0.12383s

======================================================================
Inspecting script file control_flow.R...

File contents are:

**********************************************************************
a <- TRUE
if (a == TRUE) {
    print ("a is TRUE")
} else {
    print ("a is FALSE")
}

z <- runif(1) ## Generate a uniformly distributed random number
if (z <= 0.5) {print ("Less than a half")}

for (i in 1:10) {
    j <- i * i
    print(paste(i, " squared is", j ))
}

for(species in c('Heliodoxa rubinoides', 
                 'Boissonneaua jardini', 
                 'Sula nebouxii')) {
      print(paste('The species is', species))
}

v1 <- c("a","bc","def")
for (i in v1) {
    print(i)
}

i <- 0
while (i < 10) {
    i <- i+1
    print(i^2)
}
**********************************************************************

Testing control_flow.R...

Output (only first 500 characters): 


**********************************************************************
[1] "a is TRUE"
[1] "1  squared is 1"
[1] "2  squared is 4"
[1] "3  squared is 9"
[1] "4  squared is 16"
[1] "5  squared is 25"
[1] "6  squared is 36"
[1] "7  squared is 49"
[1] "8  squared is 64"
[1] "9  squared is 81"
[1] "10  squared is 100"
[1] "The species is Heliodoxa rubinoides"
[1] "The species is Boissonneaua jardini"
[1] "The species is Sula nebouxii"
[1] "a"
[1] "bc"
[1] "def"
[1] 1
[1] 4
[1] 9
[1] 16
[1] 25
[1] 36
[1] 49
[1] 64
[1] 81
[1] 100

**********************************************************************

Code ran without errors

Time consumed = 0.09490s

======================================================================
Inspecting script file Ricker.R...

File contents are:

**********************************************************************
Ricker <- function(N0=1, r=1, K=10, generations=50)
{
  # Runs a simulation of the Ricker model
  # Returns a vector of length generations
  
  N <- rep(NA, generations)    # Creates a vector of NA
  
  N[1] <- N0
  for (t in 2:generations)
  {
    N[t] <- N[t-1] * exp(r*(1.0-(N[t-1]/K)))
  }
  return (N)
}

plot(Ricker(generations=10), type="l")

**********************************************************************

Testing Ricker.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Code ran without errors

Time consumed = 0.10806s

======================================================================
Inspecting script file MyBars.R...

File contents are:

**********************************************************************
library(ggplot2)
a <- read.table("../data/Results.txt", header = TRUE)
head(a)

a$ymin <- rep(0, dim(a)[1]) # append a column of zeros

# Print the first linerange
p <- ggplot(a)
p <- p + geom_linerange(data = a, aes(
                          x = x,
                          ymin = ymin,
                          ymax = y1,
                          size = (0.5)
                          ),
                        colour = "#E69F00",
                        alpha = 1/2, show.legend = FALSE)

# Print the second linerange
p <- p + geom_linerange(data = a, aes(
                          x = x,
                          ymin = ymin,
                          ymax = y2,
                          size = (0.5)
                          ),
                        colour = "#56B4E9",
                        alpha = 1/2, show.legend = FALSE)

# Print the third linerange:
p <- p + geom_linerange(data = a, aes(
                          x = x,
                          ymin = ymin,
                          ymax = y3,
                          size = (0.5)
                          ),
                        colour = "#D55E00",
                        alpha = 1/2, show.legend = FALSE)

# Annotate the plot with labels:
p <- p + geom_text(data = a, aes(x = x, y = -500, label = Label))

# now set the axis labels, remove the legend, and prepare for bw printing
p <- p + scale_x_continuous("My x axis",
                            breaks = seq(3, 5, by = 0.05)) + 
                            scale_y_continuous("My y axis") + 
                            theme_bw() + 
                            theme(legend.position = "none") 

# Save the plot as MyBars.pdf
ggsave("../results/MyBars.pdf", plot = p, width = 8, height = 6)

**********************************************************************

Testing MyBars.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Error in library(ggplot2) : there is no package called â€˜ggplot2â€™
Execution halted

======================================================================
Inspecting script file TreeHeight.R...

File contents are:

**********************************************************************
# Define the TreeHeight function
TreeHeight <- function(degrees, distance) {
  radians <- degrees * pi / 180
  height <- distance * tan(radians)
  return(height)
}

# Load trees.csv and calculate tree heights
trees <- read.csv("../data/trees.csv")
trees$Tree.Height.m <- TreeHeight(trees$Angle.degrees, trees$Distance.m)

# Create the output file TreeHts.csv in the results directory
output_file <- "../results/TreeHts.csv"
write.csv(trees, file = output_file, row.names = FALSE)

**********************************************************************

Testing TreeHeight.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Code ran without errors

Time consumed = 0.08271s

======================================================================
Inspecting script file get_TreeHeight.py...

File contents are:

**********************************************************************
import csv
import sys
import os
import math

# Function to calculate tree height using trigonometry
def calculate_tree_height(degrees, distance):
    # Convert angle from degrees to radians for trigonometric calculation
    radians = math.radians(degrees)
    # Calculate height using the tangent of the angle and distance
    return distance * math.tan(radians)

# Function to process data from a CSV file
def process(csv_path):    
    # Lists to store processed data and headers
    data = []
    headers = []

    # Open and read the CSV file
    with open(csv_path, 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        # Extract the header row
        headers = next(csv_reader)

        # Iterate through each row in the CSV file
        for row in csv_reader:
            # Identify column indices for angle and distance
            angle_idx = headers.index("Angle.degrees")
            distance_idx = headers.index("Distance.m")

            # Convert angle and distance values to floats
            angle_degrees = float(row[angle_idx])
            distance = float(row[distance_idx])

            # Calculate tree height and append to the row
            tree_height = calculate_tree_height(angle_degrees, distance)
            row.append(tree_height)
            data.append(row)

    # Append the new header for tree height
    headers.append("Tree.Height.m")
    return headers, data

# Function to write data to a new CSV file
def save_to_csv(savepath, headers, data):    
    # Open the output file for writing
    with open(savepath, 'w', newline='') as csv_file:
        csv_writer = csv.writer(csv_file)
        # Write the header row
        csv_writer.writerow(headers)
        # Write each data row
        for row in data:
            csv_writer.writerow(row)

# Main function to orchestrate the processing of the CSV file
def main(argv):   
    # Check for the presence of command-line argument
    if len(sys.argv) < 2:
        print("Usage: get_TreeHeight.py <filepath of csv>")
        return 1  # Error code for incorrect usage

    # Retrieve the path of the CSV file from command-line argument
    csv_path = sys.argv[1]
    # Process the CSV file
    headers, data = process(csv_path)
    # Construct a file path for saving the results
    base_name = os.path.splitext(os.path.basename(csv_path))[0]
    save_path = os.path.join("../results", f"{base_name}_treeheights.csv")
    # Save the processed data to the new CSV file
    save_to_csv(save_path, headers, data)

    return 0  # Success code

# Script entry point
if (__name__ == "__main__"):
    status = main(sys.argv)
    sys.exit(status)

**********************************************************************

Testing get_TreeHeight.py...

get_TreeHeight.py is a Python script file;

checking for docstrings...

Found one or more functions, but completely missing docstrings
2 pts deducted for missing docstring for script, and .5 pt deducted per missing docstring for function

Current Points = 95.0

Output (only first 500 characters): 


**********************************************************************
Usage: get_TreeHeight.py <filepath of csv>

**********************************************************************

Code ran without errors

Time consumed = 0.01582s

======================================================================
Inspecting script file plotLin.R...

File contents are:

**********************************************************************
library(ggplot2)
x <- seq(0, 100, by = 0.1)
y <- -4. + 0.25 * x +
  rnorm(length(x), mean = 0., sd = 2.5)

# and put them in a dataframe
my_data <- data.frame(x = x, y = y)

# perform a linear regression
my_lm <- summary(lm(y ~ x, data = my_data))

# plot the data
p <-  ggplot(my_data, aes(x = x, y = y,
                          colour = abs(my_lm$residual))
             ) +
  geom_point() +
  scale_colour_gradient(low = "black", high = "red") +
  theme(legend.position = "none") +
  scale_x_continuous(
    expression(alpha^2 * pi / beta * sqrt(Theta)))

# add the regression line
p <- p + geom_abline(
  intercept = my_lm$coefficients[1][1],
  slope = my_lm$coefficients[2][1],
  colour = "red")
# throw some math on the plot
p <- p + geom_text(aes(x = 60, y = 0,
                       label = "sqrt(alpha) * 2* pi"), 
                       parse = TRUE, size = 6, 
                       colour = "blue")

ggsave("../results/MyLinReg.pdf", plot = p, width = 8, height = 6)

**********************************************************************

Testing plotLin.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Error in library(ggplot2) : there is no package called â€˜ggplot2â€™
Execution halted

======================================================================
Inspecting script file next.R...

File contents are:

**********************************************************************
for (i in 1:10) {
  if ((i %% 2) == 0) # check if the number is odd
    next # pass to next iteration of loop 
  print(i)
}

**********************************************************************

Testing next.R...

Output (only first 500 characters): 


**********************************************************************
[1] 1
[1] 3
[1] 5
[1] 7
[1] 9

**********************************************************************

Code ran without errors

Time consumed = 0.09724s

======================================================================
Inspecting script file get_TreeHeight.R...

File contents are:

**********************************************************************
# Define the function to calculate tree height
TreeHeight <- function(degrees, distance) {
    radians <- degrees * pi / 180
    height <- distance * tan(radians)
    return (height)
}

# Obtain the command line arguments
args <- commandArgs(trailingOnly = TRUE)

# Ensure a file is provided as an argument
if(length(args) == 0) {
    stop("No file provided. Usage: get_TreeHeight.R <filename.csv>")
}

input_file <- args[1]

# Load the data
data <- read.csv(input_file, header=TRUE)

# Calculate tree heights
data$Tree.Height.m <- mapply(TreeHeight, data$Angle.degrees, data$Distance.m)

# Extract the base file name without extension and path
base_name <- tools::file_path_sans_ext(basename(input_file))

# Create the output file name
output_file <- paste0("../results/", base_name, "_treeheights.csv")

# Write the combined data to the output file
write.csv(data, file=output_file, row.names=FALSE)

**********************************************************************

Testing get_TreeHeight.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Error: No file provided. Usage: get_TreeHeight.R <filename.csv>
Execution halted

======================================================================
Inspecting script file browse.R...

File contents are:

**********************************************************************
Exponential <- function(N0 = 1, r = 1, generations = 10) {
  # Runs a simulation of exponential growth
  # Returns a vector of length generations
  
  N <- rep(NA, generations)    # Creates a vector of NA
  
  N[1] <- N0
  for (t in 2:generations) {
    N[t] <- N[t-1] * exp(r)
    browser()
  }
  return (N)
}

plot(Exponential(), type="l", main="Exponential growth")
**********************************************************************

Testing browse.R...

Output (only first 500 characters): 


**********************************************************************
Called from: Exponential()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()

**********************************************************************

Code ran without errors

Time consumed = 0.12795s

======================================================================
Inspecting script file preallocate.R...

File contents are:

**********************************************************************
NoPreallocFun <- function(x) {
    a <- vector() # empty vector
    for (i in 1:x) {
        a <- c(a, i) # concatenate
        print(a)
        print(object.size(a))
    }
}

system.time(NoPreallocFun(10))

PreallocFun <- function(x) {
    a <- rep(NA, x) # pre-allocated vector
    for (i in 1:x) {
        a[i] <- i # assign
        print(a)
        print(object.size(a))
    }
}

system.time(PreallocFun(10))

**********************************************************************

Testing preallocate.R...

Output (only first 500 characters): 


**********************************************************************
[1] 1
56 bytes
[1] 1 2
56 bytes
[1] 1 2 3
64 bytes
[1] 1 2 3 4
64 bytes
[1] 1 2 3 4 5
80 bytes
[1] 1 2 3 4 5 6
80 bytes
[1] 1 2 3 4 5 6 7
80 bytes
[1] 1 2 3 4 5 6 7 8
80 bytes
[1] 1 2 3 4 5 6 7 8 9
96 bytes
 [1]  1  2  3  4  5  6  7  8  9 10
96 bytes
   user  system elapsed 
  0.010   0.000   0.009 
 [1]  1 NA NA NA NA NA NA NA NA NA
96 bytes
 [1]  1  2 NA NA NA NA NA NA NA NA
96 bytes
 [1]  1  2  3 NA NA NA NA NA NA NA
96 bytes
 [1]  1  2  3  4 NA NA NA NA NA NA
96 bytes
 [1]  1  2  3  4  5 NA N
**********************************************************************

Code ran without errors

Time consumed = 0.11793s

======================================================================
======================================================================
Finished running scripts

Ran into 11 errors

======================================================================
======================================================================

FINISHED WEEKLY ASSESSMENT

Current Points for the Week = 95.0

NOTE THAT THESE ARE POINTS, NOT MARKS FOR THE WEEK!