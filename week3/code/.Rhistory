    return(result3)
}
## To run "num" iterations of the experiment using vectorization with lapply:
lapply_sample <- function(popn, n, num) {
    result4 <- lapply(1:num, function(i) myexperiment(popn, n))
    return(result4)
}
## To run "num" iterations of the experiment using vectorization with sapply:
sapply_sample <- function(popn, n, num) {
    result5 <- sapply(1:num, function(i) myexperiment(popn, n))
    return(result5)
}
set.seed(12345)
popn <- rnorm(10000) # Generate the population
hist(popn)
######### Functions ##########
## A function to take a sample of size n from a population "popn" and return its mean
myexperiment <- function(popn,n) {
    pop_sample <- sample(popn, n, replace = FALSE)
    return(mean(pop_sample))
}
## Calculate means using a FOR loop on a vector without preallocation:
loopy_sample1 <- function(popn, n, num) {
    result1 <- vector() #Initialize empty vector of size 1 
    for(i in 1:num) {
        result1 <- c(result1, myexperiment(popn, n))
    }
    return(result1)
}
## To run "num" iterations of the experiment using a FOR loop on a vector with preallocation:
loopy_sample2 <- function(popn, n, num) {
    result2 <- vector(,num) #Preallocate expected size
    for(i in 1:num) {
        result2[i] <- myexperiment(popn, n)
    }
    return(result2)
}
## To run "num" iterations of the experiment using a FOR loop on a list with preallocation:
loopy_sample3 <- function(popn, n, num) {
    result3 <- vector("list", num) #Preallocate expected size
    for(i in 1:num) {
        result3[[i]] <- myexperiment(popn, n)
    }
    return(result3)
}
## To run "num" iterations of the experiment using vectorization with lapply:
lapply_sample <- function(popn, n, num) {
    result4 <- lapply(1:num, function(i) myexperiment(popn, n))
    return(result4)
}
## To run "num" iterations of the experiment using vectorization with sapply:
sapply_sample <- function(popn, n, num) {
    result5 <- sapply(1:num, function(i) myexperiment(popn, n))
    return(result5)
}
set.seed(12345)
popn <- rnorm(10000) # Generate the population
hist(popn)
n <- 100 # sample size for each experiment
num <- 10000 # Number of times to rerun the experiment
print("Using loops without preallocation on a vector took:" )
print(system.time(loopy_sample1(popn, n, num)))
print("Using loops with preallocation on a vector took:" )
print(system.time(loopy_sample2(popn, n, num)))
print("Using loops with preallocation on a list took:" )
print(system.time(loopy_sample3(popn, n, num)))
print("Using the vectorized sapply function (on a list) took:" )
print(system.time(sapply_sample(popn, n, num)))
print("Using the vectorized lapply function (on a list) took:" )
print(system.time(lapply_sample(popn, n, num)))
Ricker <- function(N0=1, r=1, K=10, generations=50)
{
  # Runs a simulation of the Ricker model
  # Returns a vector of length generations
  
  N <- rep(NA, generations)    # Creates a vector of NA
  
  N[1] <- N0
  for (t in 2:generations)
  {
    N[t] <- N[t-1] * exp(r*(1.0-(N[t-1]/K)))
  }
  return (N)
}
plot(Ricker(generations=10), type="l")
# Runs the stochastic Ricker equation with gaussian fluctuations
rm(list = ls())
stochrick <- function(p0 = runif(1000, .5, 1.5), r = 1.2, K = 1, sigma = 0.2,numyears = 100)
{
  N <- matrix(NA, numyears, length(p0))  #initialize empty matrix
  N[1, ] <- p0
  for (pop in 1:length(p0)) { #loop through the populations
    for (yr in 2:numyears){ #for each pop, loop through the years
      N[yr, pop] <- N[yr-1, pop] * exp(r * (1 - N[yr - 1, pop] / K) + rnorm(1, 0, sigma)) # add one fluctuation from normal distribution
    
     }
  
  }
 return(N)
}
# Now write another function called stochrickvect that vectorizes the above to
# the extent possible, with improved performance: 
# print("Vectorized Stochastic Ricker takes:")
# print(system.time(res2<-stochrickvect()))
Ricker <- function(N0=1, r=1, K=10, generations=50)
{
  # Runs a simulation of the Ricker model
  # Returns a vector of length generations
  
  N <- rep(NA, generations)    # Creates a vector of NA
  
  N[1] <- N0
  for (t in 2:generations)
  {
    N[t] <- N[t-1] * exp(r*(1.0-(N[t-1]/K)))
  }
  return (N)
}
plot(Ricker(generations=10), type="l")
# Runs the stochastic Ricker equation with gaussian fluctuations
rm(list = ls())
stochrick <- function(p0 = runif(1000, .5, 1.5), r = 1.2, K = 1, sigma = 0.2,numyears = 100)
{
  N <- matrix(NA, numyears, length(p0))  #initialize empty matrix
  N[1, ] <- p0
  for (pop in 1:length(p0)) { #loop through the populations
    for (yr in 2:numyears){ #for each pop, loop through the years
      N[yr, pop] <- N[yr-1, pop] * exp(r * (1 - N[yr - 1, pop] / K) + rnorm(1, 0, sigma)) # add one fluctuation from normal distribution
    
     }
  
  }
 return(N)
}
print("Stochastic Ricker takes:")
print(system.time(res1<-stochrick()))
# Now write another function called stochrickvect that vectorizes the above to
# the extent possible, with improved performance: 
rm(list = ls())
stochrickvect <- function(p0 = runif(1000, .5, 1.5), r = 1.2, K = 1, sigma = 0.2,numyears = 100) {
  
  # initial matrix
  N <- matrix(NA, numyears, length(p0))
  
  # Store the initial number of individuals in the matrix rows for the first year
  N[1, ] <- p0
  
  # Modelling the stochastic Ricker equation using matrix operations to add fluctuations from a normal distribution
  for (yr in 2:numyears) {
    N[yr, ] <- N[yr-1, ] * exp(r * (1 - N[yr - 1, ] / K) + rnorm(length(p0), 0, sigma))
  }
  
  return(N)
}
print("Vectorized Stochastic Ricker takes:")
print(system.time(res2<-stochrickvect()))
# print("Vectorized Stochastic Ricker takes:")
# print(system.time(res2<-stochrickvect()))
# Runs the stochastic Ricker equation with gaussian fluctuations
rm(list = ls())
stochrick <- function(p0 = runif(1000, .5, 1.5), r = 1.2, K = 1, sigma = 0.2,numyears = 100)
{
  N <- matrix(NA, numyears, length(p0))  #initialize empty matrix
  N[1, ] <- p0
  for (pop in 1:length(p0)) { #loop through the populations
    for (yr in 2:numyears){ #for each pop, loop through the years
      N[yr, pop] <- N[yr-1, pop] * exp(r * (1 - N[yr - 1, pop] / K) + rnorm(1, 0, sigma)) # add one fluctuation from normal distribution
    
     }
  
  }
 return(N)
}
print("Stochastic Ricker takes:")
print(system.time(res1<-stochrick()))
# Now write another function called stochrickvect that vectorizes the above to
# the extent possible, with improved performance: 
stochrickvect <- function(p0 = runif(1000, .5, 1.5), r = 1.2, K = 1, sigma = 0.2,numyears = 100) {
  
  # initial matrix
  N <- matrix(NA, numyears, length(p0))
  
  # Store the initial number of individuals in the matrix rows for the first year
  N[1, ] <- p0
  
  # Modelling the stochastic Ricker equation using matrix operations to add fluctuations from a normal distribution
  for (yr in 2:numyears) {
    N[yr, ] <- N[yr-1, ] * exp(r * (1 - N[yr - 1, ] / K) + rnorm(length(p0), 0, sigma))
  }
  
  return(N)
}
print("Vectorized Stochastic Ricker takes:")
print(system.time(res2<-stochrickvect()))
# print("Vectorized Stochastic Ricker takes:")
# print(system.time(res2<-stochrickvect()))
# Runs the stochastic Ricker equation with gaussian fluctuations
rm(list = ls())
stochrick <- function(p0 = runif(1000, .5, 1.5), r = 1.2, K = 1, sigma = 0.2,numyears = 100)
{
  N <- matrix(NA, numyears, length(p0))  #initialize empty matrix
  N[1, ] <- p0
  for (pop in 1:length(p0)) { #loop through the populations
    for (yr in 2:numyears){ #for each pop, loop through the years
      N[yr, pop] <- N[yr-1, pop] * exp(r * (1 - N[yr - 1, pop] / K) + rnorm(1, 0, sigma)) # add one fluctuation from normal distribution
    
     }
  
  }
 return(N)
}
print("Stochastic Ricker takes:")
print(system.time(res1<-stochrick()))
plot(stochrick(generations=10), type="l")
# Runs the stochastic Ricker equation with gaussian fluctuations
rm(list = ls())
stochrick <- function(p0 = runif(1000, .5, 1.5), r = 1.2, K = 1, sigma = 0.2,numyears = 100)
{
  N <- matrix(NA, numyears, length(p0))  #initialize empty matrix
  N[1, ] <- p0
  for (pop in 1:length(p0)) { #loop through the populations
    for (yr in 2:numyears){ #for each pop, loop through the years
      N[yr, pop] <- N[yr-1, pop] * exp(r * (1 - N[yr - 1, pop] / K) + rnorm(1, 0, sigma)) # add one fluctuation from normal distribution
    
     }
  
  }
 return(N)
}
print("Stochastic Ricker takes:")
print(system.time(res1<-stochrick()))
# Now write another function called stochrickvect that vectorizes the above to
# the extent possible, with improved performance: 
stochrickvect <- function(p0 = runif(1000, .5, 1.5), r = 1.2, K = 1, sigma = 0.2,numyears = 100) {
  
  # initial matrix
  N <- matrix(NA, numyears, length(p0))
  
  # Store the initial number of individuals in the matrix rows for the first year
  N[1, ] <- p0
  
  # Modelling the stochastic Ricker equation using matrix operations to add fluctuations from a normal distribution
  for (yr in 2:numyears) {
    N[yr, ] <- N[yr-1, ] * exp(r * (1 - N[yr - 1, ] / K) + rnorm(length(p0), 0, sigma))
  }
  
  return(N)
}
print("Vectorized Stochastic Ricker takes:")
print(system.time(res2<-stochrickvect()))
# print("Vectorized Stochastic Ricker takes:")
# print(system.time(res2<-stochrickvect()))
Exponential <- function(N0 = 1, r = 1, generations = 10) {
  # Runs a simulation of exponential growth
  # Returns a vector of length generations
  
  N <- rep(NA, generations)    # Creates a vector of NA
  
  N[1] <- N0
  for (t in 2:generations) {
    N[t] <- N[t-1] * exp(r)
    browser()
  }
  return (N)
}
plot(Exponential(), type="l", main="Exponential growth")
n
n
n
n
n
n
n
n
plot(Exponential(), type="l", main="Exponential growth")
q
Q
doit <- function(x) {
    temp_x <- sample(x, replace = TRUE)
    if(length(unique(temp_x)) > 30) {#only take mean if sample was sufficient
         print(paste("Mean of this sample was:", as.character(mean(temp_x))))
        } 
    else {
        stop("Couldn't calculate mean: too few unique values!")
        }
    }
set.seed(1345) # again, to get the same result for illustration
popn <- rnorm(50)
hist(popn)
lapply(1:15, function(i) doit(popn))
result <- lapply(1:15, function(i) try(doit(popn), FALSE))
class(result)
result
result <- vector("list", 15) #Preallocate/Initialize
for(i in 1:15) {
    result[[i]] <- try(doit(popn), FALSE)
    }
source("try.R")
source("try.R")
source("try.R")
source("try.R")
source("try.R")
source("try.R")
source("try.R")
source("try.R")
source("try.R")
source("try.R")
source("try.R")
source("try.R")
source("try.R")
# load the data
load("../data/KeyWestAnnualMeanTemperature.RData")
# calculate correlation coefficients
observed_corr <- cor(ats$Year, ats$Temp)
# set permutations
num_permutations <- 1000
# create a vector to save the random cor
random_corrs <- numeric(num_permutations)
# use permutation test
for (i in 1:num_permutations) {
  # use sample to make random arrangement
  shuffled_temps <- sample(ats$Temp)
  
  # store random correlation coefficient
  random_corrs[i] <- cor(ats$Year, shuffled_temps)
}
# compute p value
p_value <- sum(random_corrs > observed_corr) / num_permutations
# print p_value
print(paste("p value is:", p_value))
# explain in the pdf
pdf("../results/results.pdf", width = 6, height = 6)
par(mar = c(4, 4, 2, 2))
plot(ats$Year, ats$Temp, type = "l", xlab = "Year", ylab = "Temperature", main = "Key West Florida average temperature ")
abline(lm(ats$Temp ~ ats$Year), col = "red")
dev.off()
# I checked in the overleaf. Make sure put main.tex and results.pdf in the same project
\documentclass[a4paper]{article}
\usepackage{graphicx}
\usepackage{geometry}
\begin{document}
\vspace*{-2cm}
\begin{verbatim}
# load the data
load("../data/KeyWestAnnualMeanTemperature.RData")
# calculate correlation coefficients
observed_corr <- cor(ats$Year, ats$Temp)
# set permutations
num_permutations <- 1000
# create a vector to save the random cor
random_corrs <- numeric(num_permutations)
# use permutation test
for (i in 1:num_permutations) {
  # use sample to make random arrangement
  shuffled_temps <- sample(ats$Temp)
  
  # store random correlation coefficient
  random_corrs[i] <- cor(ats$Year, shuffled_temps)
}
# compute p value
p_value <- sum(random_corrs > observed_corr) / num_permutations
# print p_value
print(paste("p value is:", p_value))
# explain in the pdf
pdf("../results/results.pdf", width = 7, height = 5)
par(mar = c(4, 4, 2, 2))
plot(ats$Year, ats$Temp, type = "l", xlab = "Year", ylab = "Temperature", main = "Key West, Florida average temperature")
abline(lm(ats$Temp ~ ats$Year), col = "red")
text(1900, 24, paste("Observed correlation coefficient:", round(observed_corr, 2)), cex = 0.7)
text(1900, 24.5, paste("Approximate p-value:", round(p_value, 4)), cex = 0.7)
dev.off()
\end{verbatim}
\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.8]{results.pdf}
  \caption{Key West, Florida average temperature}
  \label{fig:temperature}
\end{figure}
\end{document}
# load the data
load("../data/KeyWestAnnualMeanTemperature.RData")
# calculate correlation coefficients
observed_corr <- cor(ats$Year, ats$Temp)
# set permutations
num_permutations <- 1000
# create a vector to save the random cor
random_corrs <- numeric(num_permutations)
# use permutation test
for (i in 1:num_permutations) {
  # use sample to make random arrangement
  shuffled_temps <- sample(ats$Temp)
  
  # store random correlation coefficient
  random_corrs[i] <- cor(ats$Year, shuffled_temps)
}
# compute p value
p_value <- sum(random_corrs > observed_corr) / num_permutations
# print p_value
print(paste("p value is:", p_value))
# explain in the pdf
pdf("../results/results.pdf", width = 6, height = 6)
par(mar = c(4, 4, 2, 2))
plot(ats$Year, ats$Temp, type = "l", xlab = "Year", ylab = "Temperature", main = "Key West Florida average temperature ")
abline(lm(ats$Temp ~ ats$Year), col = "red")
dev.off()
# load the data
load("../data/KeyWestAnnualMeanTemperature.RData")
# calculate correlation coefficients
observed_corr <- cor(ats$Year, ats$Temp)
# set permutations
num_permutations <- 1000
# create a vector to save the random cor
random_corrs <- numeric(num_permutations)
# use permutation test
for (i in 1:num_permutations) {
  # use sample to make random arrangement
  shuffled_temps <- sample(ats$Temp)
  
  # store random correlation coefficient
  random_corrs[i] <- cor(ats$Year, shuffled_temps)
}
# compute p value
p_value <- sum(random_corrs > observed_corr) / num_permutations
# print p_value
print(paste("p value is:", p_value))
# explain in the pdf
png("../results/results.pdf", width = 6, height = 6)
par(mar = c(4, 4, 2, 2))
plot(ats$Year, ats$Temp, type = "l", xlab = "Year", ylab = "Temperature", main = "Key West Florida average temperature ")
abline(lm(ats$Temp ~ ats$Year), col = "red")
dev.off()
# load the data
load("../data/KeyWestAnnualMeanTemperature.RData")
# calculate correlation coefficients
observed_corr <- cor(ats$Year, ats$Temp)
# set permutations
num_permutations <- 1000
# create a vector to save the random cor
random_corrs <- numeric(num_permutations)
# use permutation test
for (i in 1:num_permutations) {
  # use sample to make random arrangement
  shuffled_temps <- sample(ats$Temp)
  
  # store random correlation coefficient
  random_corrs[i] <- cor(ats$Year, shuffled_temps)
}
# compute p value
p_value <- sum(random_corrs > observed_corr) / num_permutations
# print p_value
print(paste("p value is:", p_value))
# explain in the pdf
png(filename= "../results/results.pdf", width = 6, height = 6)
par(mar = c(4, 4, 2, 2))
plot(ats$Year, ats$Temp, type = "l", xlab = "Year", ylab = "Temperature", main = "Key West Florida average temperature ")
abline(lm(ats$Temp ~ ats$Year), col = "red")
dev.off()
# load the data
load("../data/KeyWestAnnualMeanTemperature.RData")
# calculate correlation coefficients
observed_corr <- cor(ats$Year, ats$Temp)
# set permutations
num_permutations <- 1000
# create a vector to save the random cor
random_corrs <- numeric(num_permutations)
# use permutation test
for (i in 1:num_permutations) {
  # use sample to make random arrangement
  shuffled_temps <- sample(ats$Temp)
  
  # store random correlation coefficient
  random_corrs[i] <- cor(ats$Year, shuffled_temps)
}
# compute p value
p_value <- sum(random_corrs > observed_corr) / num_permutations
# print p_value
print(paste("p value is:", p_value))
# explain in the pdf
png(filename= "../results/results.pdf", width = 800, height = 600)
par(mar = c(4, 4, 2, 2))
plot(ats$Year, ats$Temp, type = "l", xlab = "Year", ylab = "Temperature", main = "Key West Florida average temperature ")
abline(lm(ats$Temp ~ ats$Year), col = "red")
dev.off()
# load the data
load("../data/KeyWestAnnualMeanTemperature.RData")
# calculate correlation coefficients
observed_corr <- cor(ats$Year, ats$Temp)
# set permutations
num_permutations <- 1000
# create a vector to save the random cor
random_corrs <- numeric(num_permutations)
# use permutation test
for (i in 1:num_permutations) {
  # use sample to make random arrangement
  shuffled_temps <- sample(ats$Temp)
  
  # store random correlation coefficient
  random_corrs[i] <- cor(ats$Year, shuffled_temps)
}
# compute p value
p_value <- sum(random_corrs > observed_corr) / num_permutations
# print p_value
print(paste("p value is:", p_value))
# explain in the pdf
png(filename= "../results/results.png", width = 800, height = 600)
par(mar = c(4, 4, 2, 2))
plot(ats$Year, ats$Temp, type = "l", xlab = "Year", ylab = "Temperature", main = "Key West Florida average temperature ")
abline(lm(ats$Temp ~ ats$Year), col = "red")
dev.off()
rm(list=ls())

load("../data/KeyWestAnnualMeanTemperature.RData")

# Set seed for reproducibility 
set.seed(123)

# Calculate the correlation coefficient between consecutive years
original_corr <- cor(ats$Temp[-length(ats$Temp)], ats$Temp[-1])

# Set the number of permutations
n_permutations <- 10000

# Initialize a vector to store the correlation coefficient after permutation
permuted_corrs <- numeric(n_permutations)

# Perform permutation and calculate correlation coefficients
for(i in 1:n_permutations){
  permuted_temp <- sample(ats$Temp)
  permuted_corrs[i] <- cor(permuted_temp[-length(permuted_temp)], permuted_temp[-1])
}

# p-value
p_value <- sum(permuted_corrs > original_corr) / n_permutations

# Draw raw temperature data graph
png("../results/02_time.png")
plot(ats$Year, ats$Temp, type='l', main="Key West Annual Mean Temperature", xlab="Year", ylab=expression("Temperature ("*degree*C*")"))
dev.off()

# Draw a correlation coefficient distribution map after permutation
png("../results/02_corr.png")
hist(permuted_corrs, breaks=50, main="Distribution of Correlation Coefficients from Permutations", xlab="Correlation Coefficient")
abline(v=original_corr, col="red")
dev.off()


print(paste("Approximate p-value:", p_value))

# load the data
load("../data/KeyWestAnnualMeanTemperature.RData")

# calculate correlation coefficients
observed_corr <- cor(ats$Year, ats$Temp)

# set permutations
num_permutations <- 1000

# create a vector to save the random cor
random_corrs <- numeric(num_permutations)

# use permutation test
for (i in 1:num_permutations) {
  # use sample to make random arrangement
  shuffled_temps <- sample(ats$Temp)
  
  # store random correlation coefficient
  random_corrs[i] <- cor(ats$Year, shuffled_temps)
}

# compute p value
p_value <- sum(random_corrs > observed_corr) / num_permutations

# print p_value
print(paste("p value is:", p_value))

# explain in the png
png(filename= "../results/results.png", width = 800, height = 600)
par(mar = c(4, 4, 2, 2))
plot(ats$Year, ats$Temp, type = "l", xlab = "Year", ylab = "Temperature", main = "Key West Florida average temperature ")
abline(lm(ats$Temp ~ ats$Year), col = "red")

dev.off()



# Generate histogram of random correlation coefficients 
png(filename = "../results/cor.png", width = 800, height = 600)
# Create a histogram with a density plot
hist(random_corrs, probability = TRUE, breaks=50, xlim=range(c(random_corrs, observed_corr)), 
     main="Density and Histogram of Random Correlation Coefficients", 
     xlab="Correlation Coefficient", col="gray", border="black")
# Add a density plot
dens <- density(random_corrs)
lines(dens, col="blue", lwd=2)
# Add the observed correlation line
abline(v=observed_corr, col="darkred", lwd=2, lty=2)
# Add a legend
legend("topleft", legend=c("Random Correlation Density", "Observed Correlation"), 
       col=c("blue", "darkred"), lwd=2, lty=1:2)
dev.off()




# Load required packages
library(maps)

# Load GPDD data
load("../data/GPDDFiltered.RData")

# Create world map
map("world")

# set the location points into the map shape of point is circle(by pch =16) and color is blue(by col = blue)
points(gpdd$long, gpdd$lat, col = "blue", pch = 16)

# Bias in the data analysis

# Data are too concentrated in some areas and too sparse in others, which may lead to errors in the analyses.
# Solution: average distribute points in the map may be better
